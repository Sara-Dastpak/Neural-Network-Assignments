{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfDYFcVy-Jx8",
    "outputId": "a95f4652-f1ae-418b-fbe6-5ffd937567ff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAzLFAgf--0w",
    "outputId": "9e7f4bfa-ba43-49ef-f197-736eb8bb1bba"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "3880276955e846f79f555a42d6df8301",
      "5088e97561a1486cb78aae54e6c702be",
      "1c56b7022dd24af1af12080f383fc22c",
      "a4094c5975414ecc9bbc125967057b41",
      "52037563d3dd4cacb9e6c3dd7f078ba6",
      "4a0cc0f1862041c38e14bcec38b75229",
      "03f0636c494b40f29a23084b563c0106",
      "0e3096cdebd245f5b8cae7af0a7c3bb9",
      "8210567c3d5d41b79cc7d4a40dbb6d06",
      "6643496d18504b42ad16ac24daf6fa4f",
      "1187b05a491b42f99fa90778e05efe44",
      "8ecf610b0bc84b02ac2b5c1487002eb1",
      "4bfe51d5129049cebce450bf1f30be32",
      "baad50f6a80741769cb355a70f6e9873",
      "651737a8f03d445ba06091dc255b125a",
      "cef700b36cac49ceb9f3cec7ffff27e5",
      "6a5196500cdf4258ba7d7deac8122f90",
      "fb18138783d84a8e999c12306907319d",
      "3e68a7a8607e4f328e40d1f4905ec28a",
      "b998cfad95fc4eda8603b8d76b22eeab",
      "4c68e067325f4b3fa9729f345aac5c91",
      "b72ea3253ffe43e3b183100af1e7969c",
      "99573403b2474c70a0798ace7e6b236c",
      "40f0a4e1b5f34acc8790e6f4e3addf11",
      "b969ac5936d34dd8826ddcd3b49941f3",
      "c9385484c56f437c943aefa5de197ff1",
      "62b5fa7d651e4925be23f347376dbec3",
      "c09b3f8c12584f05b3de3ecf5f0bdd08",
      "b668da9f1eae413eb544f603790e6365",
      "acd7d1e18e6c41cf87a9758d72716560",
      "cda926701788427cb53321d177bfc0b7",
      "de55ccfa70fa4e92a1a8ca95a16f0f83",
      "dee0d5dde89941eb8047dfa8e1575f4e",
      "066a2122411b4af49258b2079a54967d",
      "40dbe36f8cfb40a7a172fe42c75f4eb0",
      "9ae0eed3fe15473ab4ac34617f783c03",
      "b51edaf3cf7b49c5a6d6dd2785188776",
      "0f900a32a8274fce978c82d0a622757b",
      "ec4ddb6092944b9eb92631b7f65937e0",
      "3112cf744bb34378a893cae8fd22f034",
      "3d85c4654b6745f990253484b2b62596",
      "293ee0a16a45460db1b1d6aad05c612a",
      "ed6c8a7da4994028bb9a59e6bfe8a5ee",
      "37cd30e843ba48f1b9321279c7c9b419",
      "c6c84e84c9cb448db07a6b7036fd91c3",
      "31679284396a4d998e441019e1ab52a3",
      "295451b4f0e34ec98810ac7621aed672",
      "1a8006dd656142f2bf6871f171f9f2be",
      "25e1c27e3dc843098e6ca56a9da95448",
      "a61b267a68c74112a52c87d973f2fd44",
      "371a64e3877b4065b80009f7f031b0ab",
      "60549dfb358f472e838bb9976b9aba92",
      "4dda209aabc14109943528621e063bf9",
      "c3b802b5ddb548bea6264775ff280594",
      "6a7ccdfc34734f259b20905bef49933d",
      "ec0853aba56045788c11f72c358eed57",
      "af55d02b7c5c4b0fad7afc7e0020f18c",
      "c12efe80575e408e9b1580a839617f69",
      "4b054099f98b4ffabdbcfa582e11abef",
      "299f0caaa6724267ae8778d98f52d43b",
      "c38d174652ea437b913d4e9ab468a046",
      "9380884a652245ae9b4b08903e3388cd",
      "483c3a4d9681465bbebdd6768b483874",
      "cb364d6cca6e46d2ad3d5a58471c4d38",
      "5bbb9addfddd4c62bc83cec0b8c753d0",
      "d4eb930b284b4ea2a1bf7e116a3b0530",
      "dea9419155bb42978855f5a32979f532",
      "a7e56ee2de564f7586ae2e65068e944b",
      "72ef73179754456bb909aada00096cb2",
      "54477964125548b9ab544bd45dd49fb9",
      "c44230e6848f4ea8985ec5b56d7d6e67",
      "2857c271613c4913b2f18a1db545f56b",
      "dd070b8b885b4703bbf89e116d8ee9d4",
      "c3febbbf79c14daa9952a5946bb86fbe",
      "08a011a24af34fdc805475be3d1b8778",
      "cd3c71764fde4120b2dc6705978e49fb",
      "d8a362b883a84a8f9c1dac565a3f6cbc",
      "5a92483b731c41a788d0a0ffda0a4321",
      "5818f306a80e4203aaed8b30584755b1",
      "56307213bf844ed8b094ac58e8befebd",
      "311aae182068461e9351fa1d3b34d683",
      "07f5cc8a99e54e62a03f3d7e93954bf3",
      "768bf51b38f74ec39a0fadf855b68950",
      "34e247edf5484a2780cfa774f8587eb2",
      "a60a7fcad6a84c7bb909972afe243406",
      "8821e08a45b14decb43f1cf739150197",
      "a30a58cedd8444759359c2e4f1dc0edd",
      "adc304ebc5a84e6cb94da6a1a387b227",
      "4e717953fafe48369c76b5f256b3aa38",
      "bcc6982dba7d45ed92e9c90d4eeee03e",
      "4676bc31cb1542e0ab6bf99ad9c962b1",
      "f7deb2b8f9fc412280306a3604461711",
      "f64ca72bb1324e6b84fdf5bf1071eca0",
      "5a09d014862642d2be0415b4933bfb1e",
      "2a1e8461f72c46c59d82a029875698c4",
      "09afd9377aa046ce8f7dca59823077e9",
      "0f2fd86af73545a19a996dbc807fda13",
      "f238b340d9c845b9b5c6b323b6815851",
      "ba72630ab02c40cda869a4f5e980f54b"
     ]
    },
    "id": "wP0afgbCGsaQ",
    "outputId": "2cc1e729-8a91-4253-d7eb-1267bdd1580f"
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the dataset\n",
    "caltech101 = tfds.load('caltech101', as_supervised=True, split=['train[:90%]', 'train[90%:]', 'test'], with_info=True)\n",
    "(train_data, val_data, test_data), info = caltech101\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (150, 150)) / 255.0  # Normalize and resize\n",
    "    label = tf.one_hot(label, depth=info.features['label'].num_classes)\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data = train_data.map(preprocess).batch(32).shuffle(1000)\n",
    "val_data = val_data.map(preprocess).batch(32)\n",
    "test_data = test_data.map(preprocess).batch(32)\n",
    "\n",
    "print(\"Dataset loaded and preprocessed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5vkv02CF5BS",
    "outputId": "448fbe68-f440-4dc7-8ca9-edcfd2e8167d"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load Caltech-101 dataset using TensorFlow Datasets\n",
    "caltech101 = tfds.load('caltech101', as_supervised=True, split=['train[:90%]', 'train[90%:]', 'test'], with_info=True)\n",
    "(train_data, val_data, test_data), info = caltech101\n",
    "\n",
    "def preprocess(image, label):\n",
    "    # Resize images to 150x150 and normalize pixel values\n",
    "    image = tf.image.resize(image, (150, 150)) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Data Augmentation function\n",
    "def augment_data(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    return preprocess(image, label)\n",
    "\n",
    "# Preprocess and batch the datasets\n",
    "batch_size = 32\n",
    "train_data = train_data.map(augment_data).batch(batch_size).shuffle(1000)\n",
    "val_data = val_data.map(preprocess).batch(batch_size)\n",
    "test_data = test_data.map(preprocess).batch(batch_size)\n",
    "\n",
    "# Print dataset summary\n",
    "print(f\"Number of classes: {info.features['label'].num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-yfXm5XF9hz"
   },
   "outputs": [],
   "source": [
    "# Define the CNN model with 5x5 filters\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (5, 5), activation='leaky_relu', input_shape=(150, 150, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (5, 5), activation='leaky_relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='leaky_relu'),\n",
    "        layers.Dense(info.features['label'].num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "zMt-fzfUGBRZ",
    "outputId": "33e435c5-05bc-449d-962a-5afab782faf6"
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=15)\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Function to plot metrics\n",
    "def plot_metrics(history, title):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot metrics for the model\n",
    "plot_metrics(history, \"CNN with 5x5 Filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT4nyU_sx1VB"
   },
   "outputs": [],
   "source": [
    "# Define a function to create the model\n",
    "def create_model(regularization=None):\n",
    "    layers_list = [\n",
    "        layers.Conv2D(32, (5, 5), activation='leaky_relu', input_shape=(150, 150, 3),\n",
    "                      kernel_regularizer=regularization),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (5, 5), activation='leaky_relu', kernel_regularizer=regularization),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='leaky_relu', kernel_regularizer=regularization),\n",
    "        layers.Dropout(0.5),  # Dropout is always added\n",
    "        layers.Dense(info.features['label'].num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    model = models.Sequential(layers_list)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2YgJ4X83vWJ",
    "outputId": "3965ce68-9946-4f12-ee6e-8b913b54f954"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate models with different regularization techniques\n",
    "from tensorflow.keras import regularizers\n",
    "regularization_methods = {\n",
    "    \"Dropout Only\": None,\n",
    "    \"L1 Regularization\": regularizers.l1(0.001),\n",
    "    \"L2 Regularization\": regularizers.l2(0.001)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, reg in regularization_methods.items():\n",
    "    print(f\"\\nTraining model with {name}...\\n\")\n",
    "    model = create_model(regularization=reg)\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=15)\n",
    "    test_loss, test_accuracy = model.evaluate(test_data)\n",
    "    results[name] = {\n",
    "        \"history\": history,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    }\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "BNxjBlmY38kf",
    "outputId": "99b5944d-287d-4907-bb1f-950214ce9906"
   },
   "outputs": [],
   "source": [
    "# Function to plot metrics for comparison\n",
    "def plot_comparisons(results):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    for idx, (name, data) in enumerate(results.items()):\n",
    "        history = data[\"history\"]\n",
    "\n",
    "        # Loss Plot\n",
    "        plt.subplot(3, 2, idx * 2 + 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f\"{name} - Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Accuracy Plot\n",
    "        plt.subplot(3, 2, idx * 2 + 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f\"{name} - Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot comparison metrics\n",
    "plot_comparisons(results)\n",
    "\n",
    "# Print final results\n",
    "for name, data in results.items():\n",
    "    print(f\"{name} - Test Loss: {data['test_loss']:.2f}, Test Accuracy: {data['test_accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "K0F18QzD_fRS",
    "outputId": "6c06bf51-3422-4c34-910e-07434bb3b74d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List to store misclassified images and labels (limit to 5 for simplicity)\n",
    "misclassified_images = []\n",
    "misclassified_labels = []\n",
    "misclassified_preds = []\n",
    "\n",
    "# Process a smaller number of images from the test data (for efficiency)\n",
    "num_images_to_check = 20  # Only check 5 images to reduce computation\n",
    "\n",
    "# Test the model on a limited number of images\n",
    "for image, label in test_data.take(1):  # Take just one batch of data\n",
    "    for i in range(min(image.shape[0], num_images_to_check)):  # Limit to `num_images_to_check` images\n",
    "        single_image = image[i]  # Get one image from the batch\n",
    "        single_label = label[i]  # Get the label corresponding to the image\n",
    "\n",
    "        # Add batch dimension to single image (shape should be (1, 150, 150, 3))\n",
    "        single_image = tf.expand_dims(single_image, axis=0)\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(single_image)\n",
    "\n",
    "        # Get predicted label\n",
    "        predicted_label = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        # Check if the prediction is incorrect\n",
    "        if predicted_label != single_label:\n",
    "            misclassified_images.append(single_image[0])  # Store the original image\n",
    "            misclassified_labels.append(single_label)\n",
    "            misclassified_preds.append(predicted_label)\n",
    "\n",
    "        # Stop if we've collected enough misclassified images\n",
    "        if len(misclassified_images) >= num_images_to_check:\n",
    "            break\n",
    "    if len(misclassified_images) >= num_images_to_check:\n",
    "        break\n",
    "\n",
    "# Plot misclassified images\n",
    "def plot_misclassified_images(images, labels, preds, num_images=5):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"True: {labels[i]}, Pred: {preds[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the misclassified images\n",
    "plot_misclassified_images(misclassified_images, misclassified_labels, misclassified_preds)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
